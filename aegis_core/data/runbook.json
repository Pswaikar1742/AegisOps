[
  {
    "incident_id": "E2E-TEST-002",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 94.2%. OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak causing OOM condition at 94.2% usage",
    "action": "RESTART",
    "justification": "Critical memory leak with imminent OOM requires immediate restart to prevent service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T17:11:54.883320"
  },
  {
    "incident_id": "DEMO-MLWKWZVV",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 94.2%. Heap allocation growing. OOM killer imminent. Container DEMO-MLWKWZVV nearing limits.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak causing OOM condition at 94.2% usage",
    "action": "RESTART",
    "justification": "Critical memory leak with imminent OOM requires immediate restart to prevent service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T17:15:08.760146"
  },
  {
    "incident_id": "DEMO-MLWKX1PC",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 94.2%. Heap allocation growing. OOM killer imminent. Container DEMO-MLWKX1PC nearing limits.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak causing OOM condition at 94.2% usage",
    "action": "RESTART",
    "justification": "Critical memory leak with imminent OOM requires immediate restart to prevent service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T17:15:09.801718"
  },
  {
    "incident_id": "INC-MLWNM28P",
    "alert_type": "Network Timeout",
    "logs": "Network Timeout detected. Usage critical. Container INC-MLWNM28P nearing limits. Immediate action required.",
    "container_name": "buggy-app-v2",
    "severity": "MEDIUM",
    "root_cause": "Network connectivity issues causing timeout errors in buggy-app-v2",
    "action": "RESTART",
    "justification": "Network timeouts typically indicate connectivity or service binding issues that are resolved by restarting the container to re-establish network connections",
    "confidence": 0.8,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:30:48.175180"
  },
  {
    "incident_id": "TEST-NET-001",
    "alert_type": "Network Timeout",
    "logs": "Network timeout: connection to upstream failed repeatedly. Trace: socket timeout. Retrying...",
    "container_name": "buggy-app-v2",
    "severity": "HIGH",
    "root_cause": "Network connectivity issues causing repeated upstream connection timeouts",
    "action": "RESTART",
    "justification": "Based on runbook knowledge, network timeouts indicate connectivity or service binding issues that are resolved by restarting the container to re-establish network connections",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:39:17.553926"
  },
  {
    "incident_id": "ba8eb9df-b727-438f-8fc8-624468bc4dda",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 85.2%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 85.2% usage",
    "action": "RESTART",
    "justification": "Memory usage at 85.2% indicates a developing memory leak that will likely lead to OOM condition. Past incidents show this pattern requires immediate restart to prevent service disruption.",
    "confidence": 0.85,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:42:47.555730"
  },
  {
    "incident_id": "c577d417-26e0-4ea4-93ad-8624c358bc41",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 85.3%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 85.3% usage",
    "action": "RESTART",
    "justification": "Memory leak at 85.3% shows clear upward trend toward OOM condition. Past incidents at 94.2% required restart - acting proactively before reaching that critical state",
    "confidence": 0.85,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:42:51.297495"
  },
  {
    "incident_id": "a2ee876b-4ffa-46c2-863e-b9e150e70ed0",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 86.4%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 86.4% usage",
    "action": "RESTART",
    "justification": "Memory usage at 86.4% indicates imminent OOM condition. Past incidents show restart is effective for memory leaks before reaching 94%+ critical levels",
    "confidence": 0.85,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:42:54.863447"
  },
  {
    "incident_id": "0ce89d64-3c6c-4117-9dfb-c1a017f9edce",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 85.1%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 85.1% usage",
    "action": "RESTART",
    "justification": "Memory usage at 85.1% indicates a memory leak pattern similar to past incidents. Proactive restart prevents OOM kill and service disruption",
    "confidence": 0.85,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:42:58.343453"
  },
  {
    "incident_id": "4487b8f3-daf3-41c3-9c2c-a1a7a541df64",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 85.1%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 85.1% usage",
    "action": "RESTART",
    "justification": "Memory usage at 85.1% indicates a memory leak pattern identical to past incident #1. Proactive restart prevents OOM kill and service disruption based on proven runbook knowledge",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:29.666509"
  },
  {
    "incident_id": "895c7b7b-98c2-407f-adef-abfb17c98776",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 85.1%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 85.1% usage",
    "action": "RESTART",
    "justification": "Memory usage at 85.1% indicates a memory leak pattern identical to past incident #1. Proactive restart prevents OOM kill and service disruption based on proven runbook knowledge",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:32.651865"
  },
  {
    "incident_id": "20d2f701-a880-4228-a181-84596ed36a4c",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 90.2%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak at critical 90.2% usage threshold",
    "action": "RESTART",
    "justification": "Memory usage at 90.2% exceeds the 85% threshold seen in past incidents and indicates imminent OOM kill. Historical runbook shows restart is the proven solution for this memory leak pattern.",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:32.655656"
  },
  {
    "incident_id": "78f404af-bef2-49f3-bd90-a93e8082d848",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 87.2%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 87.2% usage",
    "action": "RESTART",
    "justification": "Memory usage at 87.2% indicates a severe memory leak pattern identical to past incidents. This is above the 85% threshold seen in previous cases and requires immediate restart to prevent OOM kill and service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:32.659388"
  },
  {
    "incident_id": "4cc8b3fb-3e1a-4167-bf35-5d40da6dff2f",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 89.3%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak reaching critical threshold at 89.3% usage",
    "action": "RESTART",
    "justification": "Memory usage at 89.3% exceeds the critical patterns seen in past incidents (85.1-85.2%). This indicates an advanced memory leak that will imminently cause OOM kill. Past runbook knowledge confirms RESTART is the proven solution for this pattern.",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:32.677917"
  },
  {
    "incident_id": "13b3324f-9e7a-4ac6-8ece-f8448d790e47",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 87.6%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 87.6% usage",
    "action": "RESTART",
    "justification": "Memory usage at 87.6% indicates a severe memory leak pattern identical to past incidents. This is higher than previous cases (85.1%, 85.2%) that required restart. Immediate restart prevents OOM kill and service disruption.",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:32.682051"
  },
  {
    "incident_id": "430a8057-2ddd-4f1b-aee4-edf80f3a86a6",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 87.7%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak approaching critical threshold at 87.7% usage",
    "action": "RESTART",
    "justification": "Memory usage at 87.7% indicates a critical memory leak pattern identical to past incidents. This exceeds the 85% threshold seen in previous cases and requires immediate restart to prevent OOM kill and service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:32.685832"
  },
  {
    "incident_id": "dbf72099-3589-4cf7-8930-494fbe158d4b",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 89.4%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak reaching critical threshold at 89.4% usage",
    "action": "RESTART",
    "justification": "Memory usage at 89.4% is significantly higher than past incidents (85.1-85.2%) and indicates imminent OOM condition. Historical runbook knowledge shows this pattern requires immediate restart to prevent service disruption.",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:45:59.295370"
  },
  {
    "incident_id": "5b2addec-91e6-46a0-834f-03460e65e330",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 92.4%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak at critical 92.4% usage, OOM kill imminent",
    "action": "RESTART",
    "justification": "Memory usage at 92.4% exceeds the 85.1% threshold from past incidents. This follows the exact same pattern as incidents #1 and #2 but at even higher severity. Immediate restart required to prevent OOM kill and service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:46:02.623477"
  },
  {
    "incident_id": "ca0af280-c086-4b3f-b83a-67d366f638c8",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 92.2%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak at critical 92.2% usage, OOM kill imminent",
    "action": "RESTART",
    "justification": "Memory usage at 92.2% exceeds the 85.1% threshold from past incidents. This follows the same memory leak pattern but is more severe. Immediate restart required to prevent OOM kill and service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:46:04.615417"
  },
  {
    "incident_id": "3f7e8f3b-a528-430d-985e-c6d3e14263d8",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 94.5%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak causing OOM condition at 94.5% usage",
    "action": "RESTART",
    "justification": "Critical memory leak with imminent OOM requires immediate restart to prevent service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:46:07.880338"
  },
  {
    "incident_id": "d693225a-7c63-4021-b7d5-3d5bc95cd013",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 93.7%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak at critical 93.7% usage, OOM kill imminent",
    "action": "RESTART",
    "justification": "Memory usage at 93.7% exceeds the 85.1% threshold from past incidents. This follows the proven pattern from runbook knowledge where memory leaks at high usage require immediate restart to prevent OOM kill and service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:46:07.893521"
  },
  {
    "incident_id": "d4797159-f37c-471c-a61d-4262ae3c8932",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 95.0%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Memory leak reaching critical 95.0% usage with imminent OOM risk",
    "action": "RESTART",
    "justification": "Memory usage at 95.0% is significantly higher than past incidents at 85.1%, indicating severe memory leak requiring immediate restart to prevent OOM kill and service disruption",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:46:11.157066"
  },
  {
    "incident_id": "4707ccaf-bbeb-4dce-88b8-507b47051784",
    "alert_type": "Memory Leak",
    "logs": "Memory usage at 96.9%. Potential OOM imminent.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Critical memory leak at 96.9% usage with imminent OOM risk",
    "action": "RESTART",
    "justification": "Memory usage at 96.9% is critically high and exceeds the 85.1% threshold from past incidents. Immediate restart required to prevent OOM kill and service disruption. Pattern matches previous memory leak incidents but at much higher severity.",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T18:46:14.769163"
  },
  {
    "incident_id": "INC-MLWP57TF",
    "alert_type": "Memory Leak",
    "logs": "Memory Leak detected. Usage critical. Container INC-MLWP57TF nearing limits. Immediate action required.",
    "container_name": "buggy-app-v2",
    "severity": "HIGH",
    "root_cause": "Memory leak causing critical usage levels in buggy-app-v2 container",
    "action": "RESTART",
    "justification": "Critical memory leak requires immediate restart to prevent OOM kill and service disruption, consistent with past incident #2 resolution",
    "confidence": 0.9,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:13:31.306878"
  },
  {
    "incident_id": "INC-MLWP9Z2L",
    "alert_type": "OOM Kill",
    "logs": "OOM Kill detected. Usage critical. Container INC-MLWP9Z2L nearing limits. Immediate action required.",
    "container_name": "buggy-app-v2",
    "severity": "CRITICAL",
    "root_cause": "Out of Memory kill occurred in buggy-app-v2 container",
    "action": "RESTART",
    "justification": "OOM kill requires immediate restart to restore service availability, similar to past memory-related incidents",
    "confidence": 0.9,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:17:12.803767"
  },
  {
    "incident_id": "INC-MLWPYPZ7",
    "alert_type": "Disk Full",
    "logs": "Disk Full detected. Usage critical. Container INC-MLWPYPZ7 nearing limits. Immediate action required.",
    "container_name": "buggy-app-v2",
    "severity": "MEDIUM",
    "root_cause": "Disk space exhaustion in buggy-app-v2 container reaching critical limits",
    "action": "RESTART",
    "justification": "Disk full condition requires restart to clear temporary files and logs, preventing service degradation and potential crashes",
    "confidence": 0.85,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:36:27.611401"
  },
  {
    "incident_id": "DEMO-NET-1771702679",
    "alert_type": "Network Connectivity",
    "logs": "Connection timeout on 10.0.1.5:443. Retransmit rate: 95%. All services degraded.",
    "container_name": "unknown",
    "severity": "critical",
    "root_cause": "Network connectivity failure with 95% retransmit rate causing service degradation",
    "action": "RESTART",
    "justification": "Based on runbook knowledge, network timeouts indicate connectivity or service binding issues that are resolved by restarting the container to re-establish network connections. The 95% retransmit rate confirms severe network issues requiring immediate restart.",
    "confidence": 0.9,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:38:22.327507"
  },
  {
    "incident_id": "DEMO-CPU-1771702694",
    "alert_type": "CPU Spike",
    "logs": "Process PID 2847 consuming 85% CPU. Stack trace shows infinite loop in data processor.",
    "container_name": "unknown",
    "severity": "high",
    "root_cause": "Infinite loop in data processor causing CPU spike",
    "action": "RESTART",
    "justification": "Infinite loop indicates a code logic issue that won't resolve with scaling - requires process restart to break the loop",
    "confidence": 0.9,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:38:37.540821"
  },
  {
    "incident_id": "DEMO-CPU-1771702702",
    "alert_type": "CPU Spike",
    "logs": "Process PID 2847 consuming 85% CPU. Stack trace shows infinite loop in data processor.",
    "container_name": "unknown",
    "severity": "high",
    "root_cause": "Infinite loop in data processor causing CPU spike",
    "action": "RESTART",
    "justification": "Infinite loop indicates code defect that won't resolve with scaling; restart will break the loop and restore normal operation",
    "confidence": 0.9,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:38:42.076729"
  },
  {
    "incident_id": "DEMO-MEM-1771702737",
    "alert_type": "Memory Leak",
    "logs": "Memory consumption increasing: 450MB \u2192 920MB in 5 mins. OOM killer active.",
    "container_name": "unknown",
    "severity": "critical",
    "root_cause": "Rapid memory leak with OOM killer active, memory doubled in 5 minutes",
    "action": "RESTART",
    "justification": "Critical memory leak with active OOM killer requires immediate restart to prevent service disruption and restore normal memory usage",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:39:17.858057"
  },
  {
    "incident_id": "DEMO-NET-1771702778",
    "alert_type": "Network Connectivity",
    "logs": "Connection timeout on 10.0.1.5:443. Retransmit rate: 95%. All services degraded.",
    "container_name": "unknown",
    "severity": "critical",
    "root_cause": "Network connectivity failure with 95% retransmit rate causing service degradation",
    "action": "RESTART",
    "justification": "Based on runbook knowledge, network timeouts indicate connectivity or service binding issues that are resolved by restarting the container to re-establish network connections. The 95% retransmit rate confirms severe network issues requiring immediate restart.",
    "confidence": 0.95,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:40:09.875728"
  },
  {
    "incident_id": "INC-MLWQ3J9E",
    "alert_type": "Network Timeout",
    "logs": "Network Timeout detected. Usage critical. Container INC-MLWQ3J9E nearing limits. Immediate action required.",
    "container_name": "buggy-app-v2",
    "severity": "MEDIUM",
    "root_cause": "Network connectivity issues causing timeout errors in buggy-app-v2",
    "action": "RESTART",
    "justification": "Network timeouts typically indicate connectivity or service binding issues that are resolved by restarting the container to re-establish network connections. Past incident #1 with 44.3% similarity had identical symptoms and was successfully resolved with RESTART action.",
    "confidence": 0.85,
    "council_approved": true,
    "replicas_used": 0,
    "resolved_at": "2026-02-21T19:40:11.363927"
  }
]
